{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agency Data Analysis in Python\n",
    "\n",
    "This version does some things the `R` version does not, specifically optimizing hyperparameter tuning. It implicitly (through the `sklearn` libraries) uses multiprocessing too. The end result is a superior score.\n",
    "\n",
    "Part of this analysis is also instructional; while only one algorithm is used (`DecisionTreeClassifier`), any could have been used with proper hyperparameter tuning through `RamdomizedSearchCV` (cross-validation tuning).\n",
    "\n",
    "Let's get to it Boppers. Set up the data et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - let this stand alone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Not much to note here, except how `groupby` is used with a `lambda` function to filter out `transaction_type` categories with 3 or fewer instances. The algo complains (logically) about too few instances if there are three or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original agency df shape: (2376, 14)\n",
      "Agency df pruned shape: (2376, 12)\n",
      "Agency data used shape: (2371, 12)\n"
     ]
    }
   ],
   "source": [
    "# Data load and prune\n",
    "agency_df = pd.read_excel(\"../data/AgencyData_clean.xlsx\")\n",
    "print(\"Original agency df shape:\", agency_df.shape)\n",
    "\n",
    "# Trim the phat\n",
    "agency_df_pruned = agency_df.drop(['account_name', 'branch_name'], axis=1)\n",
    "print(\"Agency df pruned shape:\", agency_df_pruned.shape)\n",
    "\n",
    "# Need to remove values for transaction_type that have too few instances\n",
    "agency_df_used = agency_df_pruned.groupby('transaction_type').filter(lambda x : len(x)>3)\n",
    "print(\"Agency data used shape:\", agency_df_used.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding Reusable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df, feature):\n",
    "    # encode\n",
    "    df = pd.concat([df,pd.get_dummies(df[feature], prefix=feature)],axis=1)\n",
    "    # now drop the field, it's no longer needed\n",
    "    df.drop([feature],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the Data\n",
    "\n",
    "For the algo to work, the data has to be numeric, even the categorical data. To facilitate this, I used one-hot encoding (the function in the last code block) for the ordinal categorical data - i.e., any feature that's a list of text options, they are converted to either '1' or '0' (with columns for each value), where `1` indicates the text value **is** that option and `0` means it is **not* that option.\n",
    "\n",
    "The `policy_term` is ordinal since 6 months is always less than 12 months. For that, I used a very simple function to convert to `0` or `1`, since there are only two options.\n",
    "\n",
    "I finally had to convert the effective data to the integer representation of the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_df_used = ohe(agency_df_used, 'account_type')\n",
    "agency_df_used = ohe(agency_df_used, 'assigned_agent')\n",
    "agency_df_used = ohe(agency_df_used, 'lob')\n",
    "agency_df_used = ohe(agency_df_used, 'master_company')\n",
    "agency_df_used = ohe(agency_df_used, 'policy_type')\n",
    "agency_df_used = ohe(agency_df_used, 'rating_state')\n",
    "agency_df_used = ohe(agency_df_used, 'status')\n",
    "\n",
    "# Simple replace for ordinal value\n",
    "policy_term_mapper = {\"6 Months\": 1, \"12 Months\":2}\n",
    "agency_df_used.replace(policy_term_mapper, inplace=True)\n",
    "\n",
    "# Convert the time\n",
    "agency_df_used['eff_date_int'] = pd.to_datetime(agency_df_used['effective_date']).astype(np.int64)\n",
    "agency_df_used.drop(['effective_date'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set features, target, test, and train\n",
    "\n",
    "The target is `transaction_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target\n",
    "target = agency_df_used['transaction_type']\n",
    "features = agency_df_used.loc[:, agency_df_used.columns != 'transaction_type']\n",
    "\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla DecisionTreeClassifer\n",
    "\n",
    "Without cross-validation parameter tuning, you'd get a pretty bad score. Here's proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bland accuracy score: 58.178752%\n"
     ]
    }
   ],
   "source": [
    "dt_class_bland = DecisionTreeClassifier(random_state=0)\n",
    "dt_class_bland.fit(features_train, target_train)\n",
    "y_predict = dt_class_bland.predict(features_test)\n",
    "acc = accuracy_score(target_test, y_predict)\n",
    "print(\"Bland accuracy score:\", format(acc, '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup and Execution\n",
    "\n",
    "A lot is about to happen. First, specific parameters for the `DecisionTreeClassifier` from `sklearn` are setup. You can add/remove from this list and alter the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_features': 'sqrt', 'max_depth': 60, 'splitter': 'random', 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1}\n",
      "Best score: 70.584927%\n",
      "Error score: raise\n",
      "Scoring? None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up cross validation validator\n",
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'criterion': criterion,\n",
    "               'splitter': splitter,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "def randomSearchCV(the_grid):\n",
    "    decision_tree_classifier = DecisionTreeClassifier(random_state=0)\n",
    "    rtc_random = RandomizedSearchCV(estimator = decision_tree_classifier,\n",
    "                                    param_distributions = the_grid, n_iter = 100,\n",
    "                                    cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rtc_random.fit(features_train, target_train)\n",
    "    return rtc_random\n",
    "\n",
    "# Running in main enables multiprocessor functionality\n",
    "if __name__ == '__main__':\n",
    "    rtc = randomSearchCV(random_grid)\n",
    "    print(\"Best parameters:\", rtc.best_params_)\n",
    "    print(\"Best score:\", format(rtc.best_score_, '%'))\n",
    "    print(\"Error score:\", rtc.error_score)\n",
    "    print(\"Scoring?\", rtc.scoring)\n",
    "    the_predict = rtc.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The tuned score improvement is shown below. This is quite good and done without very deep hyperparameter tuning. I think more can be done with both the parameters used and the value options noted within the `random_grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Improvement:  12.406175%\n"
     ]
    }
   ],
   "source": [
    "    score_improvement = format(rtc.best_score_ - acc, '%')\n",
    "    print(\"Score Improvement: \", score_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
