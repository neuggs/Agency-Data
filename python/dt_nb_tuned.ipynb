{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agency Data Analysis in Python\n",
    "\n",
    "This version does some things the `R` version does not, specifically optimizing hyperparameter tuning and using different algorithms for the predictions. It implicitly (through the `sklearn` libraries) uses multiprocessing too. I'll compare and contrast what I did in `R` as well.\n",
    "\n",
    "Part of this analysis is also instructional; while only two algorithms are used (`DecisionTreeClassifier` and `GaussianNB`), any could have been used with proper hyperparameter tuning through `RamdomizedSearchCV` (cross-validation tuning).\n",
    "\n",
    "Let's get to it Boppers. Set up the data et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - let this stand alone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Not much to note here, except how `groupby` is used with a `lambda` function to filter out `transaction_type` categories with 3 or fewer instances. The algo complains (logically) about too few instances if there are three or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original agency df shape: (2376, 14)\n",
      "Agency df pruned shape: (2376, 12)\n",
      "Agency data used shape: (2371, 12)\n"
     ]
    }
   ],
   "source": [
    "# Data load and prune\n",
    "agency_df = pd.read_excel(\"../data/AgencyData_clean.xlsx\")\n",
    "print(\"Original agency df shape:\", agency_df.shape)\n",
    "\n",
    "# Trim the phat\n",
    "agency_df_pruned = agency_df.drop(['account_name', 'branch_name'], axis=1)\n",
    "print(\"Agency df pruned shape:\", agency_df_pruned.shape)\n",
    "\n",
    "# Need to remove values for transaction_type that have too few instances\n",
    "agency_df_used = agency_df_pruned.groupby('transaction_type').filter(lambda x : len(x)>3)\n",
    "print(\"Agency data used shape:\", agency_df_used.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding Reusable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df, feature):\n",
    "    # encode\n",
    "    df = pd.concat([df,pd.get_dummies(df[feature], prefix=feature)],axis=1)\n",
    "    # now drop the field, it's no longer needed\n",
    "    df.drop([feature],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the Data\n",
    "\n",
    "For the algo to work, the data has to be numeric, even the categorical data. To facilitate this, I used one-hot encoding (the function in the last code block) for the ordinal categorical data - i.e., any feature that's a list of text options, they are converted to either '1' or '0' (with columns for each value), where `1` indicates the text value **is** that option and `0` means it is **not* that option.\n",
    "\n",
    "The `policy_term` is ordinal since 6 months is always less than 12 months. For that, I used a very simple function to convert to `0` or `1`, since there are only two options.\n",
    "\n",
    "I finally had to convert the effective data to the integer representation of the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_df_used = ohe(agency_df_used, 'account_type')\n",
    "agency_df_used = ohe(agency_df_used, 'assigned_agent')\n",
    "agency_df_used = ohe(agency_df_used, 'lob')\n",
    "agency_df_used = ohe(agency_df_used, 'master_company')\n",
    "agency_df_used = ohe(agency_df_used, 'policy_type')\n",
    "agency_df_used = ohe(agency_df_used, 'rating_state')\n",
    "agency_df_used = ohe(agency_df_used, 'status')\n",
    "\n",
    "# Simple replace for ordinal value\n",
    "policy_term_mapper = {\"6 Months\": 1, \"12 Months\":2}\n",
    "agency_df_used.replace(policy_term_mapper, inplace=True)\n",
    "\n",
    "# Convert the time\n",
    "agency_df_used['eff_date_int'] = pd.to_datetime(agency_df_used['effective_date']).astype(np.int64)\n",
    "agency_df_used.drop(['effective_date'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set features, target, test, and train\n",
    "\n",
    "The target is `transaction_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target\n",
    "target = agency_df_used['transaction_type']\n",
    "features = agency_df_used.loc[:, agency_df_used.columns != 'transaction_type']\n",
    "\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla DecisionTreeClassifer and GaussianNB\n",
    "\n",
    "Without cross-validation parameter tuning, you'd get a pretty bad score. Here's proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bland DecisionTree Classifier accuracy score: 58.178752%\n",
      "Bland Naive Bayes Classifier accuracy score: 47.892074%\n"
     ]
    }
   ],
   "source": [
    "dt_class_bland = DecisionTreeClassifier(random_state=0)\n",
    "dt_class_bland.fit(features_train, target_train)\n",
    "y_predict = dt_class_bland.predict(features_test)\n",
    "acc_dt = accuracy_score(target_test, y_predict)\n",
    "print(\"Bland DecisionTree Classifier accuracy score:\", format(acc_dt, '%'))\n",
    "\n",
    "nb_class_bland = GaussianNB()\n",
    "nb_class_bland.fit(features_train, target_train)\n",
    "y_predict = nb_class_bland.predict(features_test)\n",
    "acc_nb = accuracy_score(target_test, y_predict)\n",
    "print(\"Bland Naive Bayes Classifier accuracy score:\", format(acc_nb, '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup and Execution\n",
    "\n",
    "A lot is about to happen. First, specific parameters for the `DecisionTreeClassifier` and `GaussianNB` from `sklearn` are setup. You can add/remove from this list and alter the available options.\n",
    "\n",
    "From there, a GridSearchCV (cross validation) is run with each classifier and each grid. Then the training data is fit and the scores output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Best score: 0.7137232845894264\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: {}\n",
      "Best score: 0.5264341957255344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "def randomSearchCV(classifier, the_grid):\n",
    "    rtc_random = GridSearchCV(estimator=classifier,\n",
    "                              param_grid=the_grid,\n",
    "                              cv = 3, verbose=2, n_jobs = -1)\n",
    "    rtc_random.fit(features_train, target_train)\n",
    "    return rtc_random\n",
    "\n",
    "# Running in main enables multiprocessor functionality\n",
    "if __name__ == '__main__':\n",
    "    scores_dict = {}\n",
    "\n",
    "    dt_random_grid = {'criterion': ['gini'],\n",
    "               'splitter': ['best', 'random'],\n",
    "               'max_features': [None, 'auto'],\n",
    "               'min_samples_split': [2, 3, 4, 5],\n",
    "               'min_samples_leaf': [1, 2, 3, 4]}\n",
    "\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=0)\n",
    "    rtc_dt = randomSearchCV(dt_classifier, dt_random_grid)\n",
    "    print(\"Best parameters:\", rtc_dt.best_params_)\n",
    "    print(\"Best score:\", rtc_dt.best_score_)\n",
    "\n",
    "    nb_random_grid = {}\n",
    "    nb_classifier = GaussianNB()\n",
    "    rtc_nb = randomSearchCV(nb_classifier, nb_random_grid)\n",
    "    print(\"Best parameters:\", rtc_nb.best_params_)\n",
    "    print(\"Best score:\", rtc_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The tuned score improvement is quite good and done without very deep hyperparameter tuning. I think more can be done with both the parameters used and the value options noted within the `random_grid`.\n",
    "\n",
    "For my last project, I'll improve upon this to go much deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Improvement:  0.13193576351016834\n",
      "Naive Bayes Improvement:  0.04751345373565247\n"
     ]
    }
   ],
   "source": [
    "score_imp_df = rtc_dt.best_score_ - acc_dt\n",
    "print(\"Decision Tree Improvement: \", score_imp_df)\n",
    "\n",
    "score_imp_nb = rtc_nb.best_score_ - acc_nb\n",
    "print(\"Naive Bayes Improvement: \", score_imp_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
